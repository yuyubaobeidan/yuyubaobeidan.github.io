<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="《Spark HA &amp; Yarn配置》Spark-Standalone-HA模式Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节点，当 master 节点出现故障时，集群就不可用">
<meta property="og:type" content="article">
<meta property="og:title" content="《Spark HA &amp; Yarn配置》">
<meta property="og:url" content="http://example.com/2022/05/22/spark3/index.html">
<meta property="og:site_name" content="我的博客">
<meta property="og:description" content="《Spark HA &amp; Yarn配置》Spark-Standalone-HA模式Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节点，当 master 节点出现故障时，集群就不可用">
<meta property="og:locale">
<meta property="article:published_time" content="2022-05-22T08:18:57.000Z">
<meta property="article:modified_time" content="2022-05-22T08:18:57.000Z">
<meta property="article:author" content="枕鱼">
<meta property="article:tag" content="spark作业">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/05/22/spark3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>《Spark HA & Yarn配置》 | 我的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">我的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/22/spark3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/yuyu.jpg">
      <meta itemprop="name" content="枕鱼">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Spark HA & Yarn配置》
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-05-22 16:18:57" itemprop="dateCreated datePublished" datetime="2022-05-22T16:18:57+08:00">2022-05-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/" itemprop="url" rel="index"><span itemprop="name">学习分享</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="《Spark-HA-amp-Yarn配置》"><a href="#《Spark-HA-amp-Yarn配置》" class="headerlink" title="《Spark HA &amp; Yarn配置》"></a>《Spark HA &amp; Yarn配置》</h1><p>Spark-Standalone-HA模式<br>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在<br>着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节<br>点，当 master 节点出现故障时，集群就不可用了。 spark-Standalone-HA 模式下<br>master 节点不固定，当一个宕机时，立即换另一台为 master 保障不出现故障。<br>此处因为先前配置时的 zookeeper 版本和 spark 版本不太兼容，导致此模式有故障，需要重新下<br>载配置新的版本的 zookeeper<br>配置之前需要删除三台主机的 旧版 zookeeper 以及 对应的软连接<br>在 master 节点上重新进行前面配置的 zookeeper 操作</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   1.上传apache-zookeeper-3.7.0-bin.tar.gz 到&#x2F;export&#x2F;server&#x2F;目录下 并解压文件 2.在 &#x2F;export&#x2F;server 目录下创建软连接 3.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F; 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg 4.接上步给 zoo.cfg 添加内容 5.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas 目录在此目录下创建 myid 文件，将 1 写入进 去6.将 master 节点中 &#x2F;export&#x2F;server&#x2F;zookeeper-3.7.0 路径下内容推送给slave1 和 slave2 7.推送成功后，分别在 slave1 和 slave2 上创建软连接 8.接上步推送完成后将 slave1 和 slave2 的 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;文件夹 下的 myid 中的内容分别改为 2 和 3 配置环境变量： 因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此 处也是创建软连接的方便之处</p>
</blockquote>
</blockquote>
<p>进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 文件夹 修改 spark-env.sh 文件内容</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf<br>    vim spark-env.sh</p>
</blockquote>
</blockquote>
<p>为 83 行内容加上注释，此部分原为指定 某台主机 做 master ，加上注释后即为 任何主机都<br>可以做 master</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   结果显示：<br>     ……<br>      82 # 告知Spark的master运行在哪个机器上 83 # export SPARK_MASTER_HOST&#x3D;master<br>     ………</p>
</blockquote>
</blockquote>
<p>文末添加内容</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_DAEMON_JAVA_OPTS&#x3D;”-Dspark.deploy.recoveryMode&#x3D;ZOOKEEPER -<br>       Dspark.deploy.zookeeper.url&#x3D;master:2181,slave1:2181,slave2:2181 - Dspark.deploy.zookeeper.dir&#x3D;&#x2F;spark-ha”<br>        #spark.deploy.recoveryMode<br>        指定HA模式 基于Zookeeper实现<br>        #指定Zookeeper的连接地址<br>        #指定在Zookeeper中注册临时节点的路径</p>
</blockquote>
</blockquote>
</blockquote>
<p>分发 spark-env.sh 到 salve1 和 slave2 上</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>scp spark-env.sh slave1:/export/server/spark/conf/ 
scp spark-env.sh slave2:/export/server/spark/conf/
</code></pre>
</blockquote>
</blockquote>
<p>启动之前确保 Zookeeper 和 HDFS 均已经启动<br>启动集群:</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   #在 master 上 启动一个master 和全部worker &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh # 注意, 下面命令在 slave1 上执行 启动 slave1 上的 master 做备用 master &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-master.sh<br>    结果显示：<br>    (base) [root@master ~]# jps<br>    37328 DataNode<br>    41589 Master<br>    35798 QuorumPeerMain<br>    38521 ResourceManager<br>    46281 Jps<br>    38907 NodeManager<br>    41821 Worker<br>    36958 NameNode (base)<br>    [root@slave1 sbin]# jps<br>    36631 DataNode<br>    48135 Master<br>    35385 QuorumPeerMain<br>    37961 NodeManager<br>    40970 Worker<br>    48282 Jps<br>    37276 SecondaryNameNode</p>
</blockquote>
</blockquote>
<p>访问 WebUI 界面</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>http://master:8081/
</code></pre>
<p>   <a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
<p>此时 kill 掉 master 上的 master 假设 master 主机宕机掉</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   #master主机 master 的进程号 kill -9 41589 结果显示： (base) [root@master ~]# jps 37328 DataNode 90336 Jps 35798 QuorumPeerMain 38521 ResourceManager 38907 NodeManager 41821 Worker 36958 NameNode</p>
</blockquote>
</blockquote>
<p>访问 slave1 的 WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>进行主备切换的测试<br>提交一个 spark 任务到当前 活跃的 master上 :</p>
<blockquote>
<blockquote>
<blockquote>
<p>&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;master:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000</p>
</blockquote>
</blockquote>
</blockquote>
<p>复制标签 kill 掉 master 的 进程号<br>再次访问 master 的 WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:8081/">http://master:8081/</a><br>      网页访问不了！</p>
</blockquote>
</blockquote>
</blockquote>
<p>再次访问 slave1 的 WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>可以看到当前活跃的 master 提示信息</p>
<blockquote>
<blockquote>
<blockquote>
<p>(base) [root@master ~]# &#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;master:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000 22&#x2F;03&#x2F;29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect… 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection… 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect… Pi is roughly 3.140960 (base) [root@master ~]#</p>
</blockquote>
</blockquote>
</blockquote>
<p>Spark On YARN模式</p>
<blockquote>
<blockquote>
<blockquote>
<p>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无</p>
</blockquote>
</blockquote>
</blockquote>
<p>需部署Spark集群, 只要找一台服务器, 充当Spark的客户端<br>保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中 （注: 前面配置spark-Standlone 时已经配置过此项了）</p>
<blockquote>
<blockquote>
<blockquote>
<p>spark-env.sh 文件部分显示： …. 77 ## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 78 HADOOP_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop 79 YARN_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop ….</p>
</blockquote>
</blockquote>
</blockquote>
<p>链接到 YARN 中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）<br>bin&#x2F;pyspark –master yarn –deploy-mode client|cluster # –deploy-mode 选项是指定部署模式, 默认是 客户端模式 # client就是客户端模式 # cluster就是集群模式 # –deploy-mode 仅可以用在YARN模式下<br> bin&#x2F;spark-shell –master yarn –deploy-mode client|cluster<br>bin&#x2F;spark-submit –master yarn –deploy-mode client|cluster &#x2F;xxx&#x2F;xxx&#x2F;xxx.py 参数</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>  spark-submit 和 spark-shell 和 pyspark的相关参数</p>
</blockquote>
</blockquote>
<ul>
<li>bin&#x2F;pyspark: pyspark解释器spark环境 - bin&#x2F;spark-shell: scala解释器spark环境 - bin&#x2F;spark-submit: 提交jar包或Python文件执行的工具 - bin&#x2F;spark-sql: sparksql客户端工具<br>  这4个客户端工具的参数基本通用.以spark-submit 为例: bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;master:7077 xxx.py&#96;<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>  Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]<br>   Usage: spark-submit –kill [submission ID] –master [spark:&#x2F;&#x2F;…]<br>   Usage: spark-submit –status [submission ID] –master [spark:&#x2F;&#x2F;…]<br>   Usage: spark-submit run-example [options] example-class [example args] </p>
<blockquote>
</blockquote>
<p>   Options: –master MASTER_URL spark:&#x2F;&#x2F;host:port, mesos:&#x2F;&#x2F;host:port, yarn, k8s:&#x2F;&#x2F;<a href="https://host:port">https://host:port</a>, or </p>
<blockquote>
</blockquote>
<p>   local (Default: local[*]). –deploy-mode DEPLOY_MODE 部署模式 client 或者 cluster 默认是client –class CLASS_NAME 运行java或者scala class(for Java &#x2F; Scala apps). –name NAME 程序的名字 –jars JARS Comma-separated list of jars to include on the </p>
<blockquote>
</blockquote>
<p>   driver and executor classpaths. –packages Comma-separated list of maven coordinates of </p>
<blockquote>
</blockquote>
<p>   jars to include on the driver and executor classpaths. Will </p>
<blockquote>
</blockquote>
<p>   search the local maven repo, then maven central and any </p>
<blockquote>
</blockquote>
<p>   additional remote repositories given by –repositories. The </p>
<blockquote>
</blockquote>
<p>   format for the coordinates should be </p>
<blockquote>
</blockquote>
<p>   groupId:artifactId:version.<br>   –exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided in<br>– packages to avoid dependency conflicts. –repositories Comma-separated list of additional remote repositories to search for the maven coordinates given with<br> – packages.<br> –py-files PY_FILES 指定Python程序依赖的其它python文件<br> –files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).<br>  –archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor.<br> –conf,<br> -c PROP&#x3D;VALUE 手动指定配置<br> –properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf&#x2F;spark- defaults.conf. –driver-memory MEM Driver的可用内存(Default: 1024M). –driver-java-options Driver的一些Java选项 –driver-library-path Extra library path entries to pass to the driver. –driver-class-path Extra class path entries to pass to the driver. Note that jars added with –jars are automatically included in the classpath.<br> –executor-memory MEM Executor的内存 (Default: 1G).<br> –proxy-user NAME User to impersonate when submitting the application. This argument does not work with<br> –principal &#x2F;<br> –keytab.<br> –help,<br> -h 显示帮助文件<br>  –verbose,<br>  -v Print additional debug output. –version, 打印版本 Cluster deploy mode only(集群模式专属):<br>   –driver-cores NUM Driver可用的的CPU核数(Default: 1). Spark standalone or Mesos with cluster deploy mode only:<br>   –supervise 如果给定, 可以尝试重启Driver Spark standalone, Mesos or K8s with cluster deploy mode only:<br>   –kill SUBMISSION_ID 指定程序ID kill –status SUBMISSION_ID 指定程序ID 查看运行状态 Spark standalone, Mesos and Kubernetes only:<br>   –total-executor-cores NUM 整个任务可以给Executor多少个CPU核心用 Spark standalone, YARN and Kubernetes only:<br>    –executor-cores NUM 单个Executor能使用多少CPU核心 Spark on YARN and Kubernetes only(YARN模式下):<br>    –num-executors NUM Executor应该开启几个<br>    –principal PRINCIPAL Principal to be used to login to KDC.<br>    –keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only:<br>    –queue QUEUE_NAME 指定运行的YARN队列(Default: “default”)</p>
</blockquote>
</blockquote>
</li>
</ul>
<p>启动 YARN 的历史服务器</p>
<blockquote>
<blockquote>
<blockquote>
<p>cd &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;sbin .&#x2F;mr-jobhistory-daemon.sh start historyserver</p>
</blockquote>
</blockquote>
</blockquote>
<p>访问WebUI界面</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:19888/">http://master:19888/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>client 模式测试</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;spark ${SPARK_HOME}&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode client – driver-memory 512m –executor-memory 512m –num-executors 1 –total- executor-cores 2 ${SPARK_HOME}&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py</p>
</blockquote>
</blockquote>
</blockquote>
<p>cluster 模式测试</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;spark ${SPARK_HOME}&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver- memory 512m –executor-memory 512m –num-executors 1 –total-executor-cores 2 –conf “spark.pyspark.driver.python&#x3D;&#x2F;root&#x2F;anaconda3&#x2F;bin&#x2F;python3” –conf “spark.pyspark.python&#x3D;&#x2F;root&#x2F;anaconda3&#x2F;bin&#x2F;python3” ${SPARK_HOME}&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3**</p>
</blockquote>
</blockquote>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/spark%E4%BD%9C%E4%B8%9A/" rel="tag"># spark作业</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2022/05/22/spark2/" rel="next" title="《spark基础环境配置》">
      《spark基础环境配置》 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E3%80%8ASpark-HA-amp-Yarn%E9%85%8D%E7%BD%AE%E3%80%8B"><span class="nav-number">1.</span> <span class="nav-text">《Spark HA &amp; Yarn配置》</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="枕鱼"
      src="/images/yuyu.jpg">
  <p class="site-author-name" itemprop="name">枕鱼</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yuyubaobeidan" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yuyubaobeidan" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1848960105@qq.com" title="E-Mail → mailto:1848960105@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">枕鱼</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
